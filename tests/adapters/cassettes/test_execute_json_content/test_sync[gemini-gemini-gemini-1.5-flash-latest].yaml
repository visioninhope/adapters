interactions:
- request:
    body: "{\n  \"contents\": [\n    {\n      \"parts\": [\n        {\n          \"text\":
      \"Hi\\nHi\"\n        }\n      ],\n      \"role\": \"user\"\n    }\n  ],\n  \"generationConfig\":
      {}\n}"
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '155'
      Content-Type:
      - application/json
      User-Agent:
      - python-requests/2.32.3
      x-goog-api-client:
      - gl-python/3.11.6 grpc/1.64.1 gax/2.19.0 gapic/0.6.4
      x-goog-request-params:
      - model=models/gemini-1.5-flash-latest
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint
  response:
    body:
      string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\":
        [\n          {\n            \"text\": \"Hi there! How can I help you today?
        \\n\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\":
        1,\n      \"index\": 0,\n      \"safetyRatings\": [\n        {\n          \"category\":
        9,\n          \"probability\": 1\n        },\n        {\n          \"category\":
        8,\n          \"probability\": 1\n        },\n        {\n          \"category\":
        7,\n          \"probability\": 1\n        },\n        {\n          \"category\":
        10,\n          \"probability\": 1\n        }\n      ]\n    }\n  ],\n  \"usageMetadata\":
        {\n    \"promptTokenCount\": 4,\n    \"candidatesTokenCount\": 11,\n    \"totalTokenCount\":
        15\n  }\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Cache-Control:
      - private
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Fri, 21 Jun 2024 00:52:49 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=1357
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
      content-length:
      - '684'
    status:
      code: 200
      message: OK
- request:
    body: "{\n  \"generateContentRequest\": {\n    \"model\": \"models/gemini-1.5-flash-latest\",\n
      \   \"contents\": [\n      {\n        \"parts\": [\n          {\n            \"text\":
      \"Hi Hi\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\":
      {}\n  }\n}"
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '233'
      Content-Type:
      - application/json
      User-Agent:
      - python-requests/2.32.3
      x-goog-api-client:
      - gl-python/3.11.6 grpc/1.64.1 gax/2.19.0 gapic/0.6.4
      x-goog-request-params:
      - model=models/gemini-1.5-flash-latest
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:countTokens?%24alt=json%3Benum-encoding%3Dint
  response:
    body:
      string: "{\n  \"totalTokens\": 2\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Cache-Control:
      - private
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Fri, 21 Jun 2024 00:52:49 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=155
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
      content-length:
      - '23'
    status:
      code: 200
      message: OK
- request:
    body: "{\n  \"generateContentRequest\": {\n    \"model\": \"models/gemini-1.5-flash-latest\",\n
      \   \"contents\": [\n      {\n        \"parts\": [\n          {\n            \"text\":
      \"Hi there! How can I help you today? \\n\"\n          }\n        ]\n      }\n
      \   ],\n    \"generationConfig\": {}\n  }\n}"
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '266'
      Content-Type:
      - application/json
      User-Agent:
      - python-requests/2.32.3
      x-goog-api-client:
      - gl-python/3.11.6 grpc/1.64.1 gax/2.19.0 gapic/0.6.4
      x-goog-request-params:
      - model=models/gemini-1.5-flash-latest
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:countTokens?%24alt=json%3Benum-encoding%3Dint
  response:
    body:
      string: "{\n  \"totalTokens\": 12\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Cache-Control:
      - private
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Fri, 21 Jun 2024 00:52:50 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=610
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
      content-length:
      - '24'
    status:
      code: 200
      message: OK
version: 1
