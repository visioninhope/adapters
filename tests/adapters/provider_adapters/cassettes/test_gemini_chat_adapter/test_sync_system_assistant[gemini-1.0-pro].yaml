interactions:
- request:
    body: "{\n  \"contents\": [\n    {\n      \"parts\": [\n        {\n          \"text\":
      \"Hi\"\n        }\n      ],\n      \"role\": \"user\"\n    },\n    {\n      \"parts\":
      [\n        {\n          \"text\": \"Hi\"\n        }\n      ],\n      \"role\":
      \"model\"\n    },\n    {\n      \"parts\": [\n        {\n          \"text\":
      \"*Hi*\"\n        }\n      ],\n      \"role\": \"user\"\n    },\n    {\n      \"parts\":
      [\n        {\n          \"text\": \"Hi\"\n        }\n      ],\n      \"role\":
      \"user\"\n    }\n  ],\n  \"generationConfig\": {}\n}"
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '463'
      Content-Type:
      - application/json
      User-Agent:
      - python-requests/2.31.0
      x-goog-api-client:
      - gl-python/3.11.6 grpc/1.63.0 gax/2.19.0 gapic/0.6.3
      x-goog-request-params:
      - model=models/gemini-1.0-pro
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-1.0-pro:generateContent?%24alt=json%3Benum-encoding%3Dint
  response:
    body:
      string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\":
        [\n          {\n            \"text\": \"Hi!\"\n          }\n        ],\n        \"role\":
        \"model\"\n      },\n      \"finishReason\": 1,\n      \"index\": 0,\n      \"safetyRatings\":
        [\n        {\n          \"category\": 9,\n          \"probability\": 1\n        },\n
        \       {\n          \"category\": 8,\n          \"probability\": 1\n        },\n
        \       {\n          \"category\": 7,\n          \"probability\": 1\n        },\n
        \       {\n          \"category\": 10,\n          \"probability\": 1\n        }\n
        \     ]\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 10,\n
        \   \"candidatesTokenCount\": 2,\n    \"totalTokenCount\": 12\n  }\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Cache-Control:
      - private
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Fri, 17 May 2024 22:31:12 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=1248
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
      content-length:
      - '649'
    status:
      code: 200
      message: OK
- request:
    body: "{\n  \"generateContentRequest\": {\n    \"model\": \"models/gemini-1.0-pro\",\n
      \   \"contents\": [\n      {\n        \"parts\": [\n          {\n            \"text\":
      \"Hi\"\n          },\n          {\n            \"text\": \"Hi\"\n          },\n
      \         {\n            \"text\": \"Hi\"\n          },\n          {\n            \"text\":
      \"Hi\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\": {}\n
      \ }\n}"
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '371'
      Content-Type:
      - application/json
      User-Agent:
      - python-requests/2.31.0
      x-goog-api-client:
      - gl-python/3.11.6 grpc/1.63.0 gax/2.19.0 gapic/0.6.3
      x-goog-request-params:
      - model=models/gemini-1.0-pro
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-1.0-pro:countTokens?%24alt=json%3Benum-encoding%3Dint
  response:
    body:
      string: "{\n  \"totalTokens\": 4\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Cache-Control:
      - private
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Fri, 17 May 2024 22:31:12 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=141
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
      content-length:
      - '23'
    status:
      code: 200
      message: OK
- request:
    body: "{\n  \"generateContentRequest\": {\n    \"model\": \"models/gemini-1.0-pro\",\n
      \   \"contents\": [\n      {\n        \"parts\": [\n          {\n            \"text\":
      \"Hi!\"\n          }\n        ]\n      }\n    ],\n    \"generationConfig\":
      {}\n  }\n}"
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '222'
      Content-Type:
      - application/json
      User-Agent:
      - python-requests/2.31.0
      x-goog-api-client:
      - gl-python/3.11.6 grpc/1.63.0 gax/2.19.0 gapic/0.6.3
      x-goog-request-params:
      - model=models/gemini-1.0-pro
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-1.0-pro:countTokens?%24alt=json%3Benum-encoding%3Dint
  response:
    body:
      string: "{\n  \"totalTokens\": 2\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Cache-Control:
      - private
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Fri, 17 May 2024 22:31:13 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=567
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
      content-length:
      - '23'
    status:
      code: 200
      message: OK
version: 1
