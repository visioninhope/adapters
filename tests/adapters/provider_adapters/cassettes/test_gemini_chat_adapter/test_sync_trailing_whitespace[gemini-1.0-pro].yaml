interactions:
- request:
    body: "{\n  \"contents\": [\n    {\n      \"parts\": [\n        {\n          \"text\":
      \"Hi\"\n        }\n      ],\n      \"role\": \"user\"\n    },\n    {\n      \"parts\":
      [\n        {\n          \"text\": \"Hi \"\n        }\n      ],\n      \"role\":
      \"user\"\n    }\n  ],\n  \"generationConfig\": {}\n}"
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '255'
      Content-Type:
      - application/json
      User-Agent:
      - python-requests/2.31.0
      x-goog-api-client:
      - gl-python/3.11.6 grpc/1.63.0 gax/2.19.0 gapic/0.6.3
      x-goog-request-params:
      - model=models/gemini-1.0-pro
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-1.0-pro:generateContent?%24alt=json%3Benum-encoding%3Dint
  response:
    body:
      string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\":
        [\n          {\n            \"text\": \"Hello there! How can I assist you?\"\n
        \         }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\":
        1,\n      \"index\": 0,\n      \"safetyRatings\": [\n        {\n          \"category\":
        9,\n          \"probability\": 1\n        },\n        {\n          \"category\":
        8,\n          \"probability\": 1\n        },\n        {\n          \"category\":
        7,\n          \"probability\": 1\n        },\n        {\n          \"category\":
        10,\n          \"probability\": 1\n        }\n      ]\n    }\n  ],\n  \"usageMetadata\":
        {\n    \"promptTokenCount\": 5,\n    \"candidatesTokenCount\": 9,\n    \"totalTokenCount\":
        14\n  }\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Cache-Control:
      - private
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Fri, 17 May 2024 22:30:53 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=1479
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
      content-length:
      - '679'
    status:
      code: 200
      message: OK
- request:
    body: "{\n  \"generateContentRequest\": {\n    \"model\": \"models/gemini-1.0-pro\",\n
      \   \"contents\": [\n      {\n        \"parts\": [\n          {\n            \"text\":
      \"Hi\"\n          },\n          {\n            \"text\": \"Hi \"\n          }\n
      \       ]\n      }\n    ],\n    \"generationConfig\": {}\n  }\n}"
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '272'
      Content-Type:
      - application/json
      User-Agent:
      - python-requests/2.31.0
      x-goog-api-client:
      - gl-python/3.11.6 grpc/1.63.0 gax/2.19.0 gapic/0.6.3
      x-goog-request-params:
      - model=models/gemini-1.0-pro
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-1.0-pro:countTokens?%24alt=json%3Benum-encoding%3Dint
  response:
    body:
      string: "{\n  \"totalTokens\": 3\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Cache-Control:
      - private
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Fri, 17 May 2024 22:30:53 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=144
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
      content-length:
      - '23'
    status:
      code: 200
      message: OK
- request:
    body: "{\n  \"generateContentRequest\": {\n    \"model\": \"models/gemini-1.0-pro\",\n
      \   \"contents\": [\n      {\n        \"parts\": [\n          {\n            \"text\":
      \"Hello there! How can I assist you?\"\n          }\n        ]\n      }\n    ],\n
      \   \"generationConfig\": {}\n  }\n}"
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '253'
      Content-Type:
      - application/json
      User-Agent:
      - python-requests/2.31.0
      x-goog-api-client:
      - gl-python/3.11.6 grpc/1.63.0 gax/2.19.0 gapic/0.6.3
      x-goog-request-params:
      - model=models/gemini-1.0-pro
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-1.0-pro:countTokens?%24alt=json%3Benum-encoding%3Dint
  response:
    body:
      string: "{\n  \"totalTokens\": 9\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Cache-Control:
      - private
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Fri, 17 May 2024 22:30:53 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=524
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
      content-length:
      - '23'
    status:
      code: 200
      message: OK
version: 1
